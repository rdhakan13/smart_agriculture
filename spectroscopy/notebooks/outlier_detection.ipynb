{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fa3a52-7ba5-463b-8bdc-9d457475b627",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb204125-d03a-4b5b-ba82-955e6cf0dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from spectroscopy import LeafSampleReader, DataReducer, DataCleaner, TargetScaler, BaselineCorrector, Metrics, PerformancePlotter, DataSummariser\n",
    "from spectroscopy.src.utility_functions import get_working_directory, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e603062-c864-4149-8fc7-0fb46a3a127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory_path = get_working_directory()\n",
    "leaf_samples_folder_path = f\"{working_directory_path}/data/leaf_samples\"\n",
    "leaf_sample_reader = LeafSampleReader(leaf_samples_folder_path)\n",
    "ds = DataSummariser(get_working_directory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70df241b-401c-4d3d-97eb-b10ac7109f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dried_df = leaf_sample_reader.read_all_csvs(leaf_state=\"dried\")\n",
    "fresh_df = leaf_sample_reader.read_all_csvs(leaf_state=\"fresh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526f6537-9fdb-4352-ad45-7a71339a266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dried_df = DataCleaner.enforce_data_types(dried_df)\n",
    "dried_df = DataCleaner.drop_null_data(dried_df, row_threshold=0.5, target_col_threshold=0.5, feature_col_threshold=0.5)\n",
    "dried_df = DataCleaner.impute_data(dried_df, target_method=\"knn\", feature_method=\"neighbour_avg\")\n",
    "fresh_df = DataCleaner.enforce_data_types(fresh_df)\n",
    "fresh_df = DataCleaner.drop_null_data(fresh_df, row_threshold=0.5, target_col_threshold=0.5, feature_col_threshold=0.5)\n",
    "fresh_df = DataCleaner.impute_data(fresh_df, target_method=\"knn\", feature_method=\"neighbour_avg\")\n",
    "targets_dried_df = leaf_sample_reader.extract_targets(dried_df)\n",
    "targets_fresh_df = leaf_sample_reader.extract_targets(fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b19a277-8021-4119-bea1-29a26139abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([327, 380, 356, 353, 378, 361, 283, 332, 374, 350, 288, 339, 372, 295,\n",
      "       322, 310, 345, 328, 290, 340, 297, 371, 344, 354, 368, 314, 301, 349,\n",
      "       342, 285, 331, 376, 336, 308, 306, 287, 381, 284, 323, 358, 292, 294,\n",
      "       299, 286, 330, 281, 377, 335, 293, 337, 291, 357, 324, 319, 343, 303,\n",
      "       302, 309, 307, 363, 351, 312, 379, 370, 282, 317, 329, 296, 382, 383,\n",
      "       325, 320, 289, 367, 365, 359, 347, 333, 338, 300, 326, 375, 311],\n",
      "      dtype='int64')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31 entries, 29 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PC1     31 non-null     float64\n",
      " 1   PC2     31 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 744.0 bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 115 entries, 62 to 115\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PC1     115 non-null    float64\n",
      " 1   PC2     115 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 2.7 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 79 entries, 203 to 205\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PC1     79 non-null     float64\n",
      " 1   PC2     79 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.9 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 83 entries, 327 to 311\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PC1     24 non-null     float64\n",
      " 1   PC2     24 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.9 KB\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m training_df, testing_df = train_test_split(dried_df, method=\u001b[33m\"\u001b[39m\u001b[33mstratified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(training_df[training_df[\u001b[33m\"\u001b[39m\u001b[33mseason\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[32m4\u001b[39m].index)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m some, dried_indices_targets = \u001b[43mDataCleaner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\dsmp-2024-groupo2\\spectroscopy\\src\\preprocessing\\data_cleaner.py:256\u001b[39m, in \u001b[36mDataCleaner.remove_outliers\u001b[39m\u001b[34m(df, method, n_estimators, random_state, feature_outlier_threshold)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    255\u001b[39m     _ , targets_indices = DataCleaner._remove_outliers_target(df,n_estimators,random_state)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     _ , features_indices = \u001b[43mDataCleaner\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_remove_outliers_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutlier_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_outlier_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m     set1, set2 = \u001b[38;5;28mset\u001b[39m(targets_indices), \u001b[38;5;28mset\u001b[39m(features_indices)\n\u001b[32m    258\u001b[39m     outlier_indices = \u001b[38;5;28mlist\u001b[39m(set1.symmetric_difference(set2))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\dsmp-2024-groupo2\\spectroscopy\\src\\preprocessing\\data_cleaner.py:290\u001b[39m, in \u001b[36mDataCleaner._remove_outliers_features\u001b[39m\u001b[34m(df, outlier_threshold)\u001b[39m\n\u001b[32m    288\u001b[39m season_df = reduced_data[[\u001b[33m\"\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mPC2\u001b[39m\u001b[33m\"\u001b[39m]][reduced_data[\u001b[33m\"\u001b[39m\u001b[33mseason\u001b[39m\u001b[33m\"\u001b[39m] == season]\n\u001b[32m    289\u001b[39m kmeans = KMeans(n_clusters=\u001b[32m1\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseason_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m season_cluster_means.append(kmeans.cluster_centers_)\n\u001b[32m    292\u001b[39m distances = pairwise_distances_argmin_min(reduced_data[reduced_data[\u001b[33m\"\u001b[39m\u001b[33mseason\u001b[39m\u001b[33m\"\u001b[39m] == season][[\u001b[33m\"\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mPC2\u001b[39m\u001b[33m\"\u001b[39m]], kmeans.cluster_centers_)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1454\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1428\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[32m   1429\u001b[39m \n\u001b[32m   1430\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1452\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_params_vs_input(X)\n\u001b[32m   1466\u001b[39m     random_state = check_random_state(\u001b[38;5;28mself\u001b[39m.random_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "training_df, testing_df = train_test_split(dried_df, method=\"stratified\")\n",
    "print(training_df[training_df[\"season\"]==4].index)\n",
    "some, dried_indices_targets = DataCleaner.remove_outliers(training_df, method=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da12267-9b53-43d1-9323-18a069170e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 11,\n",
       " 32,\n",
       " 38,\n",
       " 40,\n",
       " 134,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 180,\n",
       " 182,\n",
       " 224,\n",
       " 269,\n",
       " 329]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dried_indices_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c964dfe6-8c2a-43a0-881b-73de5f53f86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dried_indices_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4411c6f4-46be-4071-99ff-514b494d5958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, dried_indices_features = DataCleaner.remove_outliers(dried_df, method=\"features\",feature_outlier_threshold=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc55b4eb-1791-4b75-b387-58e81158a91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 165, 167, 233, 238]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dried_indices_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d5ed674-8aed-4691-b422-31c66f029b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dried_indices_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fe0acef-3a38-42bb-8171-ee737439e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, dried_indices_both = DataCleaner.remove_outliers(dried_df, method=\"both\", feature_outlier_threshold=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97a5fa02-74f7-439c-b479-1880ebea39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 134,\n",
       " 329,\n",
       " 11,\n",
       " 269,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 32,\n",
       " 224,\n",
       " 35,\n",
       " 38,\n",
       " 166,\n",
       " 233,\n",
       " 40,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 238,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 180,\n",
       " 182]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dried_indices_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afddbc5d-285c-4922-8418-6e81b1bb4454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dried_indices_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4316a2ee-358f-4259-a534-81cc8b817ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dried_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a58749-62b2-41c6-a785-7353670c134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.38961038961039\n"
     ]
    }
   ],
   "source": [
    "print(40*100/385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64248375-190a-453c-814e-bbba8d8ff098",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fresh_indices_targets = DataCleaner.remove_outliers(fresh_df, method=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae97c060-c349-4ddf-97dd-fbbb711131c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fresh_indices_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25ce3700-96f1-41aa-8470-01a3d6382414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, fresh_indices_features = DataCleaner.remove_outliers(fresh_df, method=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51045edd-d29a-4575-a911-560b56835b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fresh_indices_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb14467b-28c9-4c75-9fc0-e0e68bc9f6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajdh\\anaconda3\\envs\\DSMP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, fresh_indices_both = DataCleaner.remove_outliers(fresh_df, method=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4484355-2e17-4118-b7c5-2c7abda27401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fresh_indices_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886240d-73af-44fb-a1ad-97bac947e460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSMP",
   "language": "python",
   "name": "dsmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
